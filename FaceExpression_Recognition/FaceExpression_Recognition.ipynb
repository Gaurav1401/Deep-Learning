{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FaceExpression_Recognition.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPDeGdgkVLuLDQ3Gb26O0JC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gaurav1401/Deep-Learning/blob/main/FaceExpression_Recognition/FaceExpression_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbynsBkyVKZn",
        "outputId": "597497b7-9870-42c3-bf3f-be576a013097"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-30 21:20:21--  https://www.dropbox.com/s/si11cws2pyho1bp/archive.zip\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.85.18, 2620:100:6035:18::a27d:5512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.85.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/si11cws2pyho1bp/archive.zip [following]\n",
            "--2021-12-30 21:20:21--  https://www.dropbox.com/s/raw/si11cws2pyho1bp/archive.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc8b788304987818086f54363542.dl.dropboxusercontent.com/cd/0/inline/Bc3VlQwrvPWXYfWGcAAyatqA1o6bwgvvRsxfkW7ZaiWdF_oxCssuYoCpB44Zoue92lVXNS7IsAFPSDRpNVy50QAH78QbP81f3QR_u9f_tgfbKpQAHr227iFqTnMA4zzvJui3mlMti34bMfTYzX0HAD1f/file# [following]\n",
            "--2021-12-30 21:20:21--  https://uc8b788304987818086f54363542.dl.dropboxusercontent.com/cd/0/inline/Bc3VlQwrvPWXYfWGcAAyatqA1o6bwgvvRsxfkW7ZaiWdF_oxCssuYoCpB44Zoue92lVXNS7IsAFPSDRpNVy50QAH78QbP81f3QR_u9f_tgfbKpQAHr227iFqTnMA4zzvJui3mlMti34bMfTYzX0HAD1f/file\n",
            "Resolving uc8b788304987818086f54363542.dl.dropboxusercontent.com (uc8b788304987818086f54363542.dl.dropboxusercontent.com)... 162.125.85.15, 2620:100:6031:15::a27d:510f\n",
            "Connecting to uc8b788304987818086f54363542.dl.dropboxusercontent.com (uc8b788304987818086f54363542.dl.dropboxusercontent.com)|162.125.85.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/Bc0GgGtKkSOFnx1TwtMwTYLWABYXKa3Jc6Kc78_38r8ZEnTxN1igU_jtLPbf_FF5nHhcms_oguyK6053u8sneVpCyeMYdr9O0m9Lb5zGshLiZhin49585qN3A5kv6AdNUPYbXfSP8OSXBjD9vY35BgR7ftm5elkSQj-n7DkNR4fednC61fqNvn32euOBM5gnmgRxeYGoKetbo5LQ5dgB71b0ylUlFrg6SbZ3AvE2rdlmrmeRSvq2wKrbxi9e0xJfMIn8Arugiyxe4CNGg3jWYBsg6_nUvnBypufjuYkh4_et9El2r1r1UIRy1wfFsQO2Cp7CzkY6R7td5PFe_82o6TYtdLNDjQKXa_YgPXg9qv0hMf2g7r56-CYw4Y7fFaIdNcc/file [following]\n",
            "--2021-12-30 21:20:22--  https://uc8b788304987818086f54363542.dl.dropboxusercontent.com/cd/0/inline2/Bc0GgGtKkSOFnx1TwtMwTYLWABYXKa3Jc6Kc78_38r8ZEnTxN1igU_jtLPbf_FF5nHhcms_oguyK6053u8sneVpCyeMYdr9O0m9Lb5zGshLiZhin49585qN3A5kv6AdNUPYbXfSP8OSXBjD9vY35BgR7ftm5elkSQj-n7DkNR4fednC61fqNvn32euOBM5gnmgRxeYGoKetbo5LQ5dgB71b0ylUlFrg6SbZ3AvE2rdlmrmeRSvq2wKrbxi9e0xJfMIn8Arugiyxe4CNGg3jWYBsg6_nUvnBypufjuYkh4_et9El2r1r1UIRy1wfFsQO2Cp7CzkY6R7td5PFe_82o6TYtdLNDjQKXa_YgPXg9qv0hMf2g7r56-CYw4Y7fFaIdNcc/file\n",
            "Reusing existing connection to uc8b788304987818086f54363542.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 63252113 (60M) [application/zip]\n",
            "Saving to: ‘archive.zip’\n",
            "\n",
            "archive.zip         100%[===================>]  60.32M  14.8MB/s    in 4.1s    \n",
            "\n",
            "2021-12-30 21:20:27 (14.8 MB/s) - ‘archive.zip’ saved [63252113/63252113]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# !wget https://www.dropbox.com/s/si11cws2pyho1bp/archive.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip -q \"/content/archive.zip\""
      ],
      "metadata": {
        "id": "dvN3cqL0Vytn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "from pathlib import Path # To play with file paths\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings as wg\n",
        "wg.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "6ZcCyv0UV8iG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = Path(\"/content/train\")\n",
        "test_path = Path(\"/content/test\")"
      ],
      "metadata": {
        "id": "r93sJYPIWzTT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(train_path.glob(\"*/*\"))[:5] # return image paths in form of Path Object"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaOSyQKle6Pz",
        "outputId": "68a19884-f00b-46c8-f5ae-fc9481f5e909"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('/content/train/happy/Training_10240470.jpg'),\n",
              " PosixPath('/content/train/happy/Training_46719576.jpg'),\n",
              " PosixPath('/content/train/happy/Training_13542808.jpg'),\n",
              " PosixPath('/content/train/happy/Training_26049115.jpg'),\n",
              " PosixPath('/content/train/happy/Training_23419201.jpg')]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "str(list(train_path.glob(\"*/*\"))[0]) # Each object need to be converted to string"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "T3vNLZtKfdER",
        "outputId": "6be8acf1-ea2c-427d-903f-4d740f76d127"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/train/happy/Training_10240470.jpg'"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_image_paths = list(train_path.glob(\"*/*\"))\n",
        "train_image_paths = list(map(lambda x: str(x), train_image_paths)) \n",
        "# Getting all paths in the form of string using map function\n",
        "\n",
        "train_image_paths[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9T81CkOUXLUQ",
        "outputId": "0cff488a-382b-4078-ebfc-02dd9e5f13dc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/train/happy/Training_10240470.jpg',\n",
              " '/content/train/happy/Training_46719576.jpg',\n",
              " '/content/train/happy/Training_13542808.jpg',\n",
              " '/content/train/happy/Training_26049115.jpg',\n",
              " '/content/train/happy/Training_23419201.jpg']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'/content/train/neutral/Training_29136162.jpg'.split(\"/\")[-2] # Getting image label from file path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OYjEQoSXl1Z3",
        "outputId": "6bbd7b79-b655-44b5-81e4-f67b58871799"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'neutral'"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting image labels for all images using map\n",
        "train_labels = list(map(lambda x: x.split(\"/\")[-2], train_image_paths)) "
      ],
      "metadata": {
        "id": "bejD3kuDl1VU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_labels), len(train_image_paths)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Uvtb_Mwl1P2",
        "outputId": "f5f1f8e5-942b-4a92-9d08-2fd87ff471c5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28709, 28709)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert all the string labels into numbers\n",
        "le = LabelEncoder()\n",
        "train_image_labels = le.fit_transform(train_labels)\n",
        "\n",
        "train_image_labels[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6E4o2Oul1K_",
        "outputId": "f0a6c855-c2ff-43d5-9b65-5c7a73ceaaf4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 3, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The numeric labels should be treated as categorical instead of continuous values\n",
        "train_image_labels = tf.keras.utils.to_categorical(train_image_labels)"
      ],
      "metadata": {
        "id": "xJLbgsrpl1HC"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_paths, val_paths, train_labels, val_labels = train_test_split(train_image_paths,\n",
        "                                                                    train_image_labels,\n",
        "                                                                    test_size = 0.2)"
      ],
      "metadata": {
        "id": "n3rMTYCFl1Dl"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_paths), len(val_paths)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5ExOrtPp4jA",
        "outputId": "e10269fb-23f4-40c9-ed69-811ccfdc1dc1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(22967, 5742)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = tf.io.read_file(train_paths[10])\n",
        "image = tf.image.decode_jpeg(image, channels = 3)"
      ],
      "metadata": {
        "id": "vtVQAW7J3uQs"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.max(tf.image.decode_jpeg(tf.io.read_file(train_paths[100])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_dbF6hj6EeU",
        "outputId": "186f3d70-753d-43e2-b4a3-19cf278c2f6c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "255"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwyItrpO39MP",
        "outputId": "ad579d0c-8d5b-49bd-c189-8e75b9956c05"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([48, 48, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "Cgrrh39n3450",
        "outputId": "35b67d88-1325-4270-d4b7-782126fd9034"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f5e88862fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.max(image), np.min(image) # Need to resize and rescale the image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWAhz7HX5mPT",
        "outputId": "33f88624-be7e-4f42-ef6e-a045af10bf04"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(238, 0)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Refer to [this](https://www.tensorflow.org/api_docs/python/tf/io/read_file) link to know more about this function**"
      ],
      "metadata": {
        "id": "XTtKdC9z1eWK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load each image in form of tensorflow object\n",
        "def load_tensor_image(img_path, label):\n",
        "    image = tf.io.read_file(img_path)\n",
        "    # decoded_img = tf.image.rgb_to_grayscale(tf.image.decode_png(image))\n",
        "    decoded_img = tf.image.decode_jpeg(image, channels = 3)\n",
        "    # final_img = tf.image.resize(decoded_img, [512, 512], method = \"nearest\")\n",
        "    \n",
        "    return decoded_img, label"
      ],
      "metadata": {
        "id": "tUefmHIuk_Ea"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Augmentation using tf.keras.sequential:- [Click here](https://www.tensorflow.org/tutorials/images/data_augmentation)**"
      ],
      "metadata": {
        "id": "C6_i4Xys6VCh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 96\n",
        "\n",
        "\n",
        "resize_and_rescale = tf.keras.Sequential([\n",
        "  tf.keras.layers.Resizing(IMG_SIZE, IMG_SIZE),\n",
        "  tf.keras.layers.Rescaling(1./255)\n",
        "])\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  tf.keras.layers.RandomFlip(\"horizontal\"),\n",
        "  tf.keras.layers.RandomRotation(0.2),\n",
        "])"
      ],
      "metadata": {
        "id": "mYV1LWqPzl9q"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "BATCH_SIZE = 32\n",
        "def get_dataset(images, labels, train = False):\n",
        "    image_paths = tf.convert_to_tensor(images)\n",
        "    labels = tf.convert_to_tensor(labels)\n",
        "    \n",
        "    image_dataset = tf.data.Dataset.from_tensor_slices(image_paths)\n",
        "    label_dataset = tf.data.Dataset.from_tensor_slices(labels)\n",
        "    \n",
        "    \n",
        "    dataset = tf.data.Dataset.zip((image_dataset, label_dataset))\n",
        "    \n",
        "    dataset = dataset.map(lambda image, label: load_tensor_image(image, label))\n",
        "    dataset = dataset.map(lambda image, label: (resize_and_rescale(image), label), \n",
        "              num_parallel_calls=AUTOTUNE)\n",
        "    dataset = dataset.shuffle(1000)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    \n",
        "    if train:\n",
        "      dataset = dataset.map(lambda image, label: (data_augmentation(image), label), \n",
        "                num_parallel_calls=AUTOTUNE)\n",
        "      \n",
        "    dataset = dataset.repeat()\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "M1d7-j-K8RRH"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = get_dataset(train_paths, train_labels, train = True)"
      ],
      "metadata": {
        "id": "LZwAnlXG-7DC"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = next(iter(train_dataset))\n",
        "print(image.shape)\n",
        "print(label.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mEg3ynJ_dBX",
        "outputId": "0b21642a-6904-4874-fb1c-21ae93808fad"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 96, 96, 3)\n",
            "(32, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = get_dataset(train_paths, train_labels) # No Augmentation"
      ],
      "metadata": {
        "id": "7DZwahx3_lcJ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = next(iter(val_dataset))\n",
        "print(image.shape)\n",
        "print(label.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMNSgnl-_y31",
        "outputId": "df852aff-6364-4d2f-e584-186a29934cc0"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 96, 96, 3)\n",
            "(32, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Using Transfer Learning For predictions**"
      ],
      "metadata": {
        "id": "tf1v7TeoG56n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "backbone = tf.keras.applications.efficientnet.EfficientNetB2(\n",
        "           include_top=False, weights='imagenet',\n",
        "           input_shape=(96,96,3)\n",
        "           )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_APCxGL_1bD",
        "outputId": "b3a2f8fa-8268-4148-b1ff-c0b765e5d988"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb2_notop.h5\n",
            "31793152/31790344 [==============================] - 0s 0us/step\n",
            "31801344/31790344 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "                backbone,\n",
        "                tf.keras.layers.GlobalAveragePooling2D(),\n",
        "                tf.keras.layers.Dense(128, activation = \"relu\"),\n",
        "                tf.keras.layers.Dense(7, activation = \"softmax\")\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUCZB7CtH7ez",
        "outputId": "6ccf046b-1ef0-436f-deaf-ceec992f5f31"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnetb2 (Functional)  (None, 3, 3, 1408)       7768569   \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 1408)             0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               180352    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 7)                 903       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,949,824\n",
            "Trainable params: 7,882,249\n",
            "Non-trainable params: 67,575\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.layers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5yfU3eeIuOC",
        "outputId": "19abc2af-4687-47e8-b6c2-9215f429ca7b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.engine.functional.Functional at 0x7f5e887f0450>,\n",
              " <keras.layers.pooling.GlobalAveragePooling2D at 0x7f5e801c0fd0>,\n",
              " <keras.layers.core.dense.Dense at 0x7f5e801c0750>,\n",
              " <keras.layers.core.dense.Dense at 0x7f5e8890c050>]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.layers[0].trainable = False"
      ],
      "metadata": {
        "id": "KTqIJodFI695"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining our callbacks\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(\"best_weights.h5\", verbose = 1, save_best_only = True, save_weights_only=True)\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(patience = 3)"
      ],
      "metadata": {
        "id": "GhgO-qGuJAwG"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_learning_rate = 0.0001\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
        "              loss= \"categorical_crossentropy\",\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "H4WYJ-TBM7K3"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_dataset,\n",
        "                    steps_per_epoch = len(train_image_paths)//BATCH_SIZE,\n",
        "                    epochs = 10,\n",
        "                    callbacks = [checkpoint, early_stop],\n",
        "                    validation_data = val_dataset,\n",
        "                    validation_steps = len(val_paths)//BATCH_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUfTG67_K2cI",
        "outputId": "a07d2dd0-caed-4843-b2e6-95c9f1005e21"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "897/897 [==============================] - ETA: 0s - loss: 1.8195 - accuracy: 0.2469\n",
            "Epoch 00001: val_loss improved from inf to 1.83174, saving model to best_weights.h5\n",
            "897/897 [==============================] - 93s 84ms/step - loss: 1.8195 - accuracy: 0.2469 - val_loss: 1.8317 - val_accuracy: 0.2497\n",
            "Epoch 2/10\n",
            "897/897 [==============================] - ETA: 0s - loss: 1.8150 - accuracy: 0.2508\n",
            "Epoch 00002: val_loss improved from 1.83174 to 1.82773, saving model to best_weights.h5\n",
            "897/897 [==============================] - 80s 89ms/step - loss: 1.8150 - accuracy: 0.2508 - val_loss: 1.8277 - val_accuracy: 0.2523\n",
            "Epoch 3/10\n",
            "897/897 [==============================] - ETA: 0s - loss: 1.8139 - accuracy: 0.2508\n",
            "Epoch 00003: val_loss improved from 1.82773 to 1.81524, saving model to best_weights.h5\n",
            "897/897 [==============================] - 76s 85ms/step - loss: 1.8139 - accuracy: 0.2508 - val_loss: 1.8152 - val_accuracy: 0.2521\n",
            "Epoch 4/10\n",
            "897/897 [==============================] - ETA: 0s - loss: 1.8127 - accuracy: 0.2492\n",
            "Epoch 00004: val_loss did not improve from 1.81524\n",
            "897/897 [==============================] - 73s 81ms/step - loss: 1.8127 - accuracy: 0.2492 - val_loss: 1.8166 - val_accuracy: 0.2524\n",
            "Epoch 5/10\n",
            "897/897 [==============================] - ETA: 0s - loss: 1.8143 - accuracy: 0.2513\n",
            "Epoch 00005: val_loss did not improve from 1.81524\n",
            "897/897 [==============================] - 82s 92ms/step - loss: 1.8143 - accuracy: 0.2513 - val_loss: 1.8165 - val_accuracy: 0.2528\n",
            "Epoch 6/10\n",
            "897/897 [==============================] - ETA: 0s - loss: 1.8133 - accuracy: 0.2512\n",
            "Epoch 00006: val_loss did not improve from 1.81524\n",
            "897/897 [==============================] - 73s 82ms/step - loss: 1.8133 - accuracy: 0.2512 - val_loss: 1.8171 - val_accuracy: 0.2537\n"
          ]
        }
      ]
    }
  ]
}